---
title: "SSPs Data Processing"
date: today
format:
  html:
    toc: true
    toc-depth: 6
    number-sections: true
    highlight-style: breeze
    theme:
      light: spacelab
      dark: darkly
    mermaid:
      theme: neutral
  pdf:
    toc: true
    toc-depth: 6
    number-sections: true
    highlight-style: breeze
editor_options: 
  chunk_output_type: console
---

# Introduction

This tutorial demonstrates the utilization of the `gtapssp` package in R for data processing. It covers various steps such as reading, transforming, and analyzing data, making it suitable for both beginners and advanced users. 

The package provides optimized and user-friendly functions to **read** data from ZIP files, **interpolate** data using **spline** and **beers** methods. The *gtapssp* functions is accompanied by detailed [manual](https://github.com/tsimonato/gtapssp/raw/master/docs/gtapssp_0.0.0.9000.pdf), you can also access this manual by running `?gtapssp` in the R console or pressing `F1` on the function name in [RStudio](https://posit.co/download/rstudio-desktop/).

# Installation

To use the *gtapssp* package, it's necessary to have *R* installed on your computer, which can be downloaded from [here](https://www.r-project.org/). Additionally, we recommend downloading *RStudio*, available at [here](https://posit.co/download/rstudio-desktop/), which provides a user-friendly interface to work with *R*.

You can install the development version of *gtapssp* from [GitHub](https://github.com/) with:

```{r}
#| label: install
#| echo: true
#| eval: false

# If the devtools package is not already installed, please run the disabled line below.
# install.packages("devtools")
devtools::install_github("tsimonato/coffeer")
devtools::install_github("tsimonato/gtapssp")
```

# Procedures

We will go through different stages of data manipulation which include reading data from ZIP files, transforming the data format, performing interpolations, and combining data from different sources.

## OECD and IIASA Data

Now, let's read the data from a ZIP file, reshape it, and interpolate it.

```{r}
OECD <- gtapssp::read_csv_from_zip( # <1>
  zip_dir = "Downloads",
  zip_pattern = "OECD",
  csv_pattern = "ssp_snapshot"
) |>
  tidyr::pivot_longer( # <2>
    cols = dplyr::matches(as.character(1500:3000)),
    names_to = "year",
    values_to = "value"
  ) |>
  gtapssp::interpolate_spline( # <3>
    groups = c("Scenario", "Region"),
    year = "year",
    values = "value",
    method = "fmm"
  ) 

```

1. `read_csv_from_zip` reads CSV files from a ZIP archive, specifying the directory of the files, name file pattern, and name CSV pattern.

2. `pivot_longer` transforms `year` columns from wide format to long format.

3. `interpolate_spline` performs data interpolation for missing years using *fmm* spline method.


We process the IIASA data similarly.

```{r}

IIASA <- gtapssp::read_csv_from_zip(
  zip_dir = "Downloads",
  zip_pattern = "IIASA", # <1>
  csv_pattern = "ssp_snapshot"
) |>
  tidyr::pivot_longer(
    cols = dplyr::matches(as.character(1500:3000)),
    names_to = "year",
    values_to = "value"
  ) |>
  gtapssp::interpolate_spline(
    groups = c("Scenario", "Region"),
    year = "year",
    values = "value"
  )
```

1. The `IIASA` field specifies the pattern to match the ZIP file names.

## WIC Data

Additional processing is done for the WIC dataset. This includes transformations and analysis with the `interpolate_beers` function.

### WIC data processing steps

```{r warning=FALSE}
#| message: false
WIC <- gtapssp::read_csv_from_zip( # <1>
  zip_dir = "Downloads",
  zip_pattern = "WIC",
  csv_pattern = "ssp_snapshot"
)

WIC <- WIC |>
  tidyr::pivot_longer( # <2>
    cols = dplyr::matches(as.character(1500:3000)),
    names_to = "year",
    values_to = "value"
  )

WIC <- WIC |>
  tidyr::separate_wider_delim( # <3>
    cols = "Variable",
    names = c("var", "gender_code", "cohort", "education_level"),
    delim = "|",
    too_few = "align_start"
  ) |>
  dplyr::mutate(year = as.integer(year)) # <4>

WIC <- gtapssp::interpolate_beers( # <5>
  input_df = WIC,
  groups = c("Scenario", "Region", "gender_code", "cohort", "education_level"),
  year = "year",
  values = "value",
  method = "ordinary"
)
# fread in csv: "C:\Users\tcsim\OneDrive\purdue_postdoc\projects\ssp\SSPV3\WIC_All_int.csv"
# i want to data.table::fread in this path: "C:\Users\tcsim\OneDrive\purdue_postdoc\projects\ssp\SSPV3\WIC_All_int.csv"

#WIC_test <-  data.table::fread("C:/Users/tcsim/OneDrive/purdue_postdoc/projects/ssp/SSPV3/WIC_All_int.csv", na.strings = "")


```

1. This command reads CSV files from a ZIP archive located in the `Downloads` directory. The function targets files with the `WIC` pattern in their name and specifically looks for files that contain `ssp_snapshot` in their name.
2. `pivot_longer` transforms `year` columns from wide format to long format.
3. The `separate_wider_delim` function is used to split the `Variable` column into multiple columns based on a delimiter `|`. This creates new columns `var`, `gender_code`, `cohort`, and `education_level`.
4. Finally, `dplyr::mutate` is used to convert the `year` column to integer type for consistent data handling.
5. `interpolate_beers` performs data interpolation for missing years using *ordinary* beers method.

### Labeling and Cleaning Data for Export

In this step, we prepare our WIC data for export by labeling and cleaning it to ensure it's in the correct format. This involves reading additional data sets and merging them with our main dataset.

```{r}
isoList_dt <- read.csv("data/isoList.csv", na.strings = "")  # <1>
educDict_dt <- read.csv("data/educDict.csv", na.strings = "")
cohortDict_dt <- read.csv("data/cohortDict.csv", na.strings = "")
genderDict_dt <- read.csv("data/genderDict.csv", na.strings = "")

WIC <- 
  WIC |> 
  dplyr::left_join(isoList_dt, by = dplyr::join_by(Region)) |>  # <2>
  dplyr::left_join(educDict_dt, by = dplyr::join_by(education_level)) |> 
  dplyr::left_join(cohortDict_dt, by = dplyr::join_by(cohort)) |> 
  dplyr::left_join(genderDict_dt, by = dplyr::join_by(gender_code))
```

1. Each `read.csv` call reads a different CSV file containing essential data. The `na.strings = ""` parameter treats empty strings as `NA` values.
2. The WIC data is joined with the additional datasets using the `dplyr::left_join`.

Finally, `dplyr::transmute` is used to transform and rename columns, resulting in a dataset ready to be exported:

```{r}
WIC <- 
  WIC |> 
  dplyr::mutate(
    SCE = Scenario,         # SSPs scenarios
    ISO = iso,              # ISO country codes for geographic identification
    EDU = educ,             # Education categories, derived from 'educ'
    GND = gender,           # Gender information
    AGE = age,              # Age groups or categories
    YRS = paste0("Y", year),# Year, formatted with a 'Y' prefix
    POP = value,             # Population values
    .keep = "none"
  )

a <- WIC |> 
  dplyr::group_by(YRS, SCE) |>
  dplyr::summarize(
    sum = sum(POP) # Sum of population values
  )

```



# Export to a HAR file

```{r}

# arrange for all variables
a <- 
  WIC |>
  dplyr::arrange(SCE, ISO, EDU, GND, AGE, YRS)


gtaptools::har_shape(
  input_data = list(list(
    input_data = WIC2, # <1>
    header = quote( # <2>
      `POP`[c( # <3>
      "SCE",
      "ISO",
      "EDU",
      "GND", # <4>
      "AGE",
      "YRS"
    )])
  )),
  output_har_file = "ssp3_gdp.har" # <5>
)



WIC2 <- WIC |>
  coffeer::order_data(
    ordering_list = list(
      SCE = unique(WIC$SCE),
      ISO = unique(WIC$ISO),
      EDU = unique(WIC$EDU),
      GND = unique(WIC$GND),
      AGE = unique(WIC$AGE),
      YRS = unique(WIC$YRS)
    )
  ) |> 
  as.data.frame()

coffeer::har_write(
  headers = list(
    WIC = list(
      data = WIC2,
      values = "POP",
      sets = c("SCE", "ISO", "EDU", "GND", "AGE", "YRS"),
      coeff = "WIC",
      name = "WIC"
    )
  )
  output_har = "WIC.har"
)






```

1. The `input_data` parameter specifies the dataset to be exported.
2. The `header` parameter defines the columns to be included in the output file.
3. The `POP` column is selected for export, with specific columns included in the output file.
4. The `GND` column is commented out to exclude it from the output file.
5. The `output_har_file` parameter specifies the name of the HAR file to be created.









```{r}
har_shape <- function(input_data,
                      useCoefficientsAsNames = F,
                      #new_calculated_vars = NULL,
                      del_headers = NULL,
                      export_sets = T,
                      output_har_file = NULL,
                      as_dataframes = T) {
  #' @name har_shape
  #' @title Bind data bases and generate/change headers.
  #'
  #' @description Allows the combination of different databases in data.frame or array format. Generate new variables flexibly from custom functions. Calculations can be performed between headers/variables of different dimensions/sets.
  #'
  #' @param input_data It must consist of one or more input databases, which must be separated from each other by sublists (see example). In the case of multiple databases, all will be combined for the final output.Arrays and data.frames must be inside sublists (list(....)) as indicated in the examples section. Aggregations on input data can only be performed on single array and data.frame inputs.
  #' @param useCoefficientsAsNames If a coefficient name is present in the header, use that instead of the four-letter header (default = F)
#  #' @param new_calculated_vars New variables resulting from custom calculations between the headers contained in #input_data. The header_name[c("its sets")] format must be adopted. The new header generated by the calculation will #be aggregated by sum in the sets indicated for it. Please check the examples section and the package's online manual #for more details.
  #' @param del_headers Vector of characters with the names of headers that must be excluded from the output.
  #' @param export_sets If a name for a .har file is indicated, all sets will exported to that .har file. If TRUE the sets will included in output_har_file, if FALSE the sets will not be written anywhere. (default = TRUE)
  #' @param output_har_file Output .har file name.
  #' @param as_dataframes Converts each sublist to data.frame format (default = T).
  #'
  #' @importFrom HARr write_har read_har
  #' @import data.table
  #'
  #' @note
  #'
  #' 1. The calculations indicated in the new_calculated_vars variable are processed sequentially. Therefore, if the calculation for generating a new header depends on another header that will also be generated within new_calculated_vars, the second one must be defined first.
  #'
  #' 2. Ensure that the .har files adopted as input_data have an adequate structure, including the declaration of sets for each file header. It prevents the output_har_file from being recorded with errors that make it impossible for the file to be opened by the Viewhar software later.
  #'
  #' @examples
  #' # example code
  #'
  #' # - The list_df is composed by list_df, a list of input data
  #' #    (path to a .har database(1), data.frame(2), list of arrays(3), array(4)).
  #'
  #' path_to_har <- gtaptools::templates("oranig_example.har")
  #'
  #' list_db <- list(
  #'   path_to_har, # 1 - path to .har database
  #'   list(
  #'     input_data = gtaptools::example_df, # 2 - data.frame
  #'     header = quote(`1MAR`[c("COM", "SRC", "IND", "MAR")])
  #'   ),
  #'   gtaptools::example_arrays_har, # 3 - list of arrays
  #'   list(
  #'     input_data = gtaptools::example_arrays_har$XPLH, # 4 - array
  #'     header = quote(`XPLH`[c("COM", "HOU")])
  #'   )
  #' )
  #'
  #' # - calcs defines the calculations that aggregate (1),
  #' #    solve a matrix (2) and create a header (3).
  #'
  #' calcs <- list(
  #'   quote(MARC["COM"] := `1MAR`), # Sums to set COM
  #'   quote(MULT[c("REG", "HOU")] := solve(MAKE)), # Solves the matrix
  #'   quote(NSET := c("Comm1", "Comm2")) # Creates sets
  #' )
  #'
  #'
  #' # - new_binded_db is a list object that combines the databases
  #' #    contained in list_df and the calculations described in calcs.
  #' #   Also, the "3PUR" header will not be included in the data output
  #' #    to "gtaptools_shape_example.har", while the sets are being
  #' #    written to "gtaptools_shape_example_sets.har"
  #'
  #'
  #' new_binded_db <-
  #'   gtaptools::har_shape(
  #'     input_data = list_db,
  #'     new_calculated_vars = calcs,
  #'     del_headers = c("3PUR"),
  #'     export_sets = "gtaptools_shape_example_sets.har",
  #'     output_har_file = "gtaptools_shape_example.har"
  #'   )
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #' @export

  #
  #   output_har_file = "test.har"
  #   del_header <- "MAKE"
  #
  #   input_data_text <- "data/test/teste/input/REG_DYN_HOU.har"
  #   input_data1 <- HARr::read_har(input_data_text,
  #     useCoefficientsAsNames = F,
  #     toLowerCase = F
  #   )
  #
  #   input_data2 <- input_data1$MAKE |> as.data.frame.table()
  #   input_data3 <- input_data1$BSMR |> as.data.frame.table()
  #   input_data4 <- input_data1$HOU
  #   input_data5 <- input_data1$MAKE
  #
  #
  #   1.04313517 + 23.37448354
  #
  #   1.04313517 + 23.37448354
  #
  #   log(19078.02545586)
  #
  #
  #   new_calculated_vars <- list(
  #     list(
  #       x = "MAKE",
  #       y = "BSMR",
  #       #z = "TFRO",
  #       fun = function(x, y) x + y,
  #       new_header = "MCID",
  #       new_sets = c("COM", "DST")
  #     ),
  #     list(
  #       x = "BSMR",
  #       fun = function(x) log(x),
  #       new_header = "BSMC",
  #       new_sets = c("COM")
  #     ),
  #     list(
  #       x = "BSMR",
  #       fun = function(x) sum(x),
  #       new_header = "BSCS",
  #       new_sets = c("COM", "SRC")
  #     )
  #   )
  #
  #   input_data <- list(
  #     input_data1,
  # list(
  #   input_data = input_data2,
  #   sets = c("COM", "IND", "DST"),
  #   values = "Freq",
  #   new_header_name = "MAKE"
  # ),
  # list(
  #   input_data = input_data3,
  #   sets = c("COM", "SRC"),
  #   values = "Freq",
  #   new_header_name = "MAKE"
  # ),
  # list(
  #   input_data = input_data4,
  #   new_header_name = "HOU"
  # )
  # )




  # new_derived_vars <- list(
  #   list(
  #     input_header = "MAKE",
  #     new_header = "MAK4",
  #     new_header_dim = c("COM", "IND")
  #   ),
  #   list(
  #     input_header = "BSMR" ,
  #     new_header = "BSM2",
  #     new_header_dim = "COM"
  #   )
  # )


  # l <- 1
  
  
  
  input_data = list(list(input_data = WIC2, # <1>
                         header = quote(# <2>
                           `POP`[c(# <3>
                             "SCE",
                             "ISO",
                             "EDU",
                             "GND", # <4>
                             "AGE",
                             "YRS")])))
    
    
    
  output_har_file = "ssp3_gdp.har" # <5>
                      useCoefficientsAsNames = F
                      new_calculated_vars = NULL
                      del_headers = NULL
                      export_sets = T
                      as_dataframes = T
  
  
  # non_obj <-
  #   unlist(input_data[!sapply(input_data, function(x)
  #     is.object(x) & is.list(x))], recursive = F)
  # obj <- input_data[sapply(input_data, is.object)]
  # input_data <- c(non_obj, obj)
                      
    
 complete_data <- function(input_data, group = NULL, values, fill_value = NA) {
  original_class <- class(input_data)
  
  # Handle array input by converting it to a data.frame
  if (is.array(input_data)) {
    dim_names <- dimnames(input_data)
    group = names(dim_names)
    input_data <- as.data.frame.table(input_data)
    names(input_data) <- c(group, values)
    for (i in seq_along(group)) {
      input_data[[group[i]]] <- factor(input_data[[group[i]]], levels = dim_names[[i]])
    }
  }
  
  # Ensure input_data is compatible with data.table operations
  if (!inherits(input_data, "data.table")) {
    data.table::setDT(input_data)
  }
  
  # Generate all combinations of group columns
  all_combos <- do.call(data.table::CJ, c(lapply(input_data[, ..group, with = FALSE], unique), sorted = FALSE))
  
  # Perform a right join to keep all combinations using all.x = TRUE
  expanded_data <- merge(all_combos, input_data, by = group, all = TRUE)
  
  # Fill NA values in specified 'values' columns with 'fill_value'
  for (value_col in values) {
    if (value_col %in% names(expanded_data)) {  # Check if the column actually exists
      if (!is.na(fill_value)) {  # Only set NAs if a fill_value is specified
        expanded_data[is.na(expanded_data[[value_col]]), (value_col) := fill_value]
      }
    } else {
      warning(sprintf("Column '%s' not found in input data. No values filled.", value_col))
    }
  }
  
  # Return the data in its original format
  if (original_class[1] == "array") {
    return(array(expanded_data[[values]], dim = dim(expanded_data[, ..group, with = FALSE]), dimnames = lapply(expanded_data[, ..group, with = FALSE], unique)))
  } else if (original_class[1] == "data.frame") {
    return(as.data.frame(expanded_data))
  } else {
    return(expanded_data)
  }
}
  
  adj_input <- function(input_array, sets, values) {
            
  completed_data =
    complete_data(
      input_data = input_array,
      group = sets,
      values = values,
      fill_value = 0
    ) |> as.data.frame()
  
 dim = rev(lapply(completed_data[sets], function(x) length(unique(x))))
 dimnames = rev(lapply(completed_data[sets], unique)) 
 order_array <- rev(1:(length(lapply(completed_data[sets], unique))))
 
new_array = array(
    as.numeric(completed_data[[values]]),
    dim = dim,
    dimnames = dimnames
  ) |> aperm(order_array)

  return(new_array)

}
  
input_data[[1]]$input_data

adj_input( input_array = input_data[[1]]$input_data, 
           sets = c("SCE", "ISO", "EDU", "GND", "AGE", "YRS"), 
           values = "POP")

  input_har <- c()
  for (l in 1:length(input_data)) {
    input <- input_data[[1]]
    
    # for (l in 1:length(input_har)) {
    #   if (is.data.frame(input_har[[l]])) {
    #     input <- as.array(input_har[[l]],
    #                       responseName = names(input_har[l]))
    #   }
    # }

    # if (is.array(input)) {
    #   stop("One or more elements of the input database list (input_data) is an array. Please insert it into a sublist and describe its new_header_name, and sets in a format new_header_name[c(its sets)].")
    # }

    if (length(input) == 1) {
      if ((is.character(input[[1]]) & grepl("*.har", input[[1]]))) {
        input <- HARr::read_har(input[[1]], toLowerCase = F,
                                useCoefficientsAsNames = useCoefficientsAsNames)

        input_har_diff <- base::setdiff(names(input_har), names(input))
        input_har <- c(input_har[input_har_diff], input)
      }
    } else if (!substr(names(input)[1], 1, 2) == "XX") {
      if (!is.null(input$input_data)) {
        sets = eval(input$header[[3]])
        values = as.character(input$header[[2]])
        input <- summarise_header(
          input_data = input$input_data,
          header = input$header,
          fun = function(x) sum(x, na.rm = T)
        )
       input <-  adj_input(
         input_array = input[[values]], 
           sets = sets, 
           values = values)
        
        input_har_diff <- base::setdiff(names(input_har), names(input))
        input_har <- c(input_har[input_har_diff], input)
      } else {
        input_har_diff <- base::setdiff(names(input_har), names(input))
        input_har <- c(input_har[input_har_diff], input)
      }
    }
  }
  
  # if (!is.null(new_calculated_vars)) {
  #   for (v in 1:length(new_calculated_vars)) {
  #     expr <- new_calculated_vars[[v]][[3]]
  # 
  #     dim_adj <- function(x) {
  #       if (is.array(x) & length(dim(x)) == 1) {
  #         x <- c(x)
  #       }
  #       return(x)
  #     }
  #     input_har_1_dim_adj <- lapply(input_har, dim_adj)
  # 
  #     result_calc <- with(input_har_1_dim_adj, eval(expr))
  # 
  #     if (is.character(result_calc)) {
  #       new_header_name <- new_calculated_vars[[v]][[2]]
  #       input_har[[new_header_name]] <- NULL
  #       input_har[[new_header_name]] <- result_calc
  #     } else {
  #       if (length(new_calculated_vars[[v]][[2]]) == 1) {
  #         new_h <- new_calculated_vars[[v]][[2]]
  #         stop(paste0(
  #           "New Header and its sets were not properly described: ",
  #           new_h,
  #           '. Please, describe it in a format: new_header_name[c("its sets")].'
  #         ))
  #       }
  # 
  #       sets <- new_calculated_vars[[v]][[2]][[3]]
  # 
  #       if (is.null(names(dimnames(result_calc)))) {
  #         result_calc <- as.array(result_calc)
  #         names(dimnames(result_calc)) <- eval(sets)
  #       } else {
  #         result_calc <- apply(result_calc, eval(sets), sum)
  #         if (is.null(names(dimnames(result_calc)))) {
  #           result_calc <- as.array(result_calc)
  #           names(dimnames(result_calc)) <- eval(sets)
  #         }
  #       }
  # 
  #       new_header_name <- new_calculated_vars[[v]][[2]][[2]]
  #       input_har[[new_header_name]] <- NULL
  #       input_har[[new_header_name]] <- result_calc
  #     }
  #   }
  # }

  if (!is.null(del_headers)) {
    input_har <- input_har[!names(input_har) %in% del_headers]
  }
  
  
  # create_ordering_list <- function(data_frame, fields) {
  #   ordering_list <- lapply(fields, function(field) {
  #     if (field %in% names(data_frame)) {
  #       unique(data_frame[[field]])
  #     } else {
  #       NULL  # If the field does not exist in 'data_frame', return NULL (default order)
  #     }
  #   })
  #   names(ordering_list) <- fields
  #   return(ordering_list)
  # }
  # 
  # 
  # 
  # # Create ordering list
  # ordering_list <- create_ordering_list(WIC, fields_to_order_by)
  # 
  # input_har <-  order_data(
  #   input_har,
  #   ordering_list = list(
  #     SCE = unique(WIC$SCE),
  #     ISO = unique(WIC$ISO),
  #     EDU = unique(WIC$EDU),
  #     GND = unique(WIC$GND),
  #     AGE = unique(WIC$AGE),
  #     YRS = unique(WIC$YRS)
  #   )
  # )
  #   input_har <-  as.data.frame(input_har)
    
    
  sets <- lapply(input_har, function(x) dimnames(x))
  sets <- unlist(sets, recursive = FALSE)
  names(sets) <- substr(names(sets), nchar(names(sets)) - 2, nchar(names(sets)))
  sets <- sets[unique(names(sets))]
  input_har_diff <- base::setdiff(names(input_har), names(sets))
  
  complete_data <- function(input_data, group, values, fill_value = NA) {
  # Ensure input_data is compatible with data.table operations
  if (!inherits(input_data, "data.table")) {
    data.table::setDT(input_data)
  }
  
  # Generate all combinations of group columns
  all_combos <- do.call(data.table::CJ, c(lapply(input_data[, ..group, with = FALSE], unique), sorted = FALSE))
  
  # Perform a right join to keep all combinations using all.x = TRUE
  expanded_data <- merge(all_combos, input_data, by = group, all = TRUE)
  
  # Fill NA values in specified 'values' columns with 'fill_value'
  for (value_col in values) {
    if (value_col %in% names(expanded_data)) {  # Check if the column actually exists
      if (!is.na(fill_value)) {  # Only set NAs if a fill_value is specified
        expanded_data[is.na(expanded_data[[value_col]]), (value_col) := fill_value]
      }
    } else {
      warning(sprintf("Column '%s' not found in input data. No values filled.", value_col))
    }
  }
  
  # Convert back to data.frame if originally a data.frame
  if (!inherits(input_data, "data.table")) {
    return(as.data.frame(expanded_data))
  }
  
  return(expanded_data)
}

  input_data[[1]]$input_data <-
    complete_data(
      input_data[[1]]$input_data,
      group = names(sets),
      values = input_har_diff,
      fill_value = 0
    )
  
 dim = rev(lapply(input_har[names(sets)], length))
 dimnames = rev(lapply(input_har[names(sets)], unique)) 
 order_array <- rev(1:(length(lapply(input_har[names(sets)], unique))))
 
data <- list(
  DAT = array(
    as.numeric(input_har[!names(input_har) %in% names(sets)][[1]]),
    dim = dim,
    dimnames = dimnames
  ) |> aperm(order_array)
)


  if (is.character(export_sets)) {
    HARr::write_har(sets, filename = export_sets)
  } else if (!export_sets | is.character(export_sets)) {
    input_har <- input_har[input_har_diff]
  } else if (export_sets) {
    input_har <- c(sets, input_har[input_har_diff])
  }
        
        
  input_har      


  if (!is.null(output_har_file)) {
    HARr::write_har(data, filename = output_har_file)
  }

  if (as_dataframes) {
    for (l in 1:length(input_har)) {
      if (is.array(input_har[[l]])) {
        input_har[[l]] <- as.data.frame.table(input_har[[l]],
                                              responseName = names(input_har[l]))
      }
    }
  }

  return(input_har)
}



summarise_header <- function(input_data,
                             header,
                             fun = function(x) sum(x, na.rm = T),
                             export_sets = T,
                             output_har_file = NULL,
                             output_csv_file = NULL,
                             ...) {
  #' @name summarise_header
  #' @title Aggregates headers of data in .har structure.
  #'
  #' @description Summarizes a single database to an array compatible format for writing to .har files.
  #'
  #' @param input_data An array that has the output structure of the read_har function or a data.frame.
  #' @param header Must be adopted the format header_name[c("its sets")], where the header_name must be the same name of the numeric values column in case of a data.frame input_data, and the "its sets" must be the same name of the categorical columns of that data.frame. Please check the examples section and the package's online manual for more details.
  #' @param fun Function used for aggregation in case of non-unique values in sets (default = sum).
  #' @param export_sets If TRUE, the vectors with the set elements are incorporated with the output. If an output .har file is indicated, it will be created and exported to that .har file. If FALSE, they will not be exported.
  #' @param output_har_file Output .har file name.
  #' @param output_csv_file Output .csv file name.
  #' @param ... Any additional arguments to be used to write the .csv file through data.table::fwrite, such as separator character (sep = ","), the character for decimal points (dec = "."), etc.
  #'
  #' @return An array or vector of characters (sets) structured in a compatible way to compose a .har file.
  #'
  #' @importFrom HARr read_har write_har
  #' @import data.table
  #'
  #' @examples
    #' # example code
    #' 

  #'
  #'
  #' @export
  #
  #   path_to_folder <- system.file("extdata", package="gtaptools")
  #
  #   data_example <- mtcars
  #   iris
  #
  #   gtaptools::summarise_header(
  #     input_data = data_example,
  #     sets = c("mpg", "cyl", "am"),
  #     values = "hp",
  #     fun = function(x) sum(x, na.rm = T),
  #     new_header_name = "CARS",
  #     export_sets = T,
  #     output_har_file = "cars_example.har"
  #   )
  #
  #
  #   input_data = data_example
  #   sets = c("mpg", "cyl", "am")
  #   values = "hp"
  #   fun = function(x) sum(x, na.rm = T)
  #   new_header_name = "CARS"
  #   export_sets = T
  #   output_har_file = "cars_example.har"


  #
  # new_var <- NULL
  # input_data_text <- "data/test/teste/input/REG_DYN_HOU.har"
  # input_data <- HARr::read_har(input_data_text,
  #   useCoefficientsAsNames = F,
  #   toLowerCase = F
  # )
  #
  # input_data2 <- input_data1$MAKE |> as.data.frame.table()
  # input_data3 <- input_data1$BSMR |> as.data.frame.table()
  # input_data3 <- input_data1$BSMR
  # input_data4 <- input_data1$HOU
  #
  # input_data <- input_data2
  #
  #
  #
  #
  #
  #
  #
  #   new_calculated_vars <- list(
  #     list(
  #       x = "MAKE",
  #       y = "1CAP",
  #       z = "TFRO",
  #       fun = function(x, y, z) sum(x + y + z),
  #       new_header = "XXXX",
  #       new_dim_cols = c("COM", "IND", "DST")
  #     ),
  #     list(
  #       x = "BSMR",
  #       fun = function(x) log(x),
  #       new_header = "YYYY",
  #       new_dim_cols = c("COM")
  #     ),
  #     list(
  #       x = "BSMR",
  #       fun = function(x) sum(x),
  #       new_header = "MAK4",
  #       new_dim_cols = c("COM", "SRC")
  #     )
  #   )
  #
  #
  #   input_data <- list(
  #     input_data1,
  #     list(
  #       data = input_data2,
  #       dim_cols = c("COM", "IND", "DST"),
  #       values = "Freq",
  #       name_header = "MAKE"
  #     ),
  #     list(
  #       data = input_data3,
  #       dim_cols = c("COM", "SRC", "USR", "DST"),
  #       values = "Freq",
  #       name_header = "MAKE2"
  #     ),
  #     list(
  #       data = input_data4,
  #       name_header = "HOU"
  #     )
  #   )




  # new_derived_vars <- list(
  #   list(
  #     input_header = "MAKE",
  #     new_header = "MAK4",
  #     new_header_dim = c("COM", "IND")
  #   ),
  #   list(
  #     input_header = "BSMR" ,
  #     new_header = "BSM2",
  #     new_header_dim = "COM"
  #   )
  # )

  # df_data = input_data2
  # sets = c("COM", "IND")
  # values = "Freq"
  # new_header_name = "OOOOO"
  #
  #
  # input_data=input_data2
  # sets = c("COM", "IND")
  # values = "Freq"
  # new_header_name = "OOOO"
  # fun = function(x) sum(x, na.rm = T)
  # output_har_file = "Test.har"
  #
  #
  # # input <- input_data1$BSMR
  #
  # df_data <- input$data

  sets <- eval(header[[3]])
  col_values <- as.character(header[[2]])
  new_header_name <- col_values

  if (!(is.data.frame(input_data) | is.array(input_data) | is.list(input_data))) {
    if (is.character(input_data) & grepl("*.har", input_data)) {
      input_data <- HARr::read_har(input_data, toLowerCase = F) # [[tolower(header)]]
      col_values <- "Freq"
    } else {
      stop("Input_data must be a data.frame, array or a path to a .har file.")
    }
  }

  # sets <- tolower(sets)

  summ_header <- function(input_data,
                          header = header,
                          fun = function(x) sum(x, na.rm = T)) {
    sets <- eval(header[[3]])
    col_values <- as.character(header[[2]])
    new_header_name <- col_values

    if (!(is.data.frame(input_data) | is.array(input_data) | is.character(input_data))) {
      stop("The input data is not a data.frame, array or a vector of characters (sets).")
    }

    if (nchar(col_values) > 4) {
      stop("The name of the new header must have up to 4 characters.")
    }

    if (is.array(input_data)) {
      input_data <- as.data.frame.table(input_data)
      col_values <- "Freq"
    }


    test <- !c(sets, col_values) %in% names(input_data)
    if (any(test)) {
      cols_null <- c(sets, col_values)[test]
      stop(paste0(col_values, ": The ", paste0(cols_null, collapse = ", "), " columns indicated in the sets and/or values parameters are not found in the input database."))
    }


    col_values <- ifelse(is.null(col_values), "Freq", col_values)

    df_data <- as.data.frame(input_data)
    df_data <- df_data[c(sets, col_values)]
    df_data[[col_values]] <- as.numeric(df_data[[col_values]])
    # df_data <- data.table::as.data.table(df_data)
    df_data <- data.table::setDT(df_data)[, lapply(.SD, fun), by = c(sets)]
    df_data <- as.data.frame(df_data)

    dim_info <- df_data[sets]
    dim <- sapply(dim_info, function(x) length(unique(x)))
    dimnam <- sapply(dim_info, function(x) unique(x))

    if (!is.list(dimnam)) {
      dimnam <- as.list(as.data.frame(dimnam))
    }

    if (any(nchar(names(dim)) > 3) & !any(names(dim) == "YEAR")) {
      stop("Set names must be up to 3 characters.")
    }

    har_data <- c()
    har_data[[new_header_name]] <- array(
      data = df_data[[col_values]],
      dim = dim,
      dimnames = dimnam
    )

    return(har_data)
  }


  input_har <- c()
  if (!is.character(input_data)) {
    # if (is.array(input_data)) {
    #   col_values <- ifelse(is.null(col_values), "Freq", col_values)
    # }

    input_har <- summ_header(input_data,
      header = header,
      fun = fun
    )

    input_har_no_sets <- input_har
    if (export_sets == T) {
      input_har <- c(input_har, dimnames(input_har[[new_header_name]]))
    }
    if (is.character(export_sets)) {
      HARr::write_har(dimnames(input_har[[new_header_name]]),
        filename = export_sets
      )
    }
  } else {
    input_data <- input_data[input_data != "NA"]
    input_data <- input_data[input_data != ""]
    input_data <- input_data[!is.na(input_data)]
    input_data <- na.omit(input_data)
    input_har[[new_header_name]] <- unique(as.character(input_data))
  }


  if (!is.null(output_har_file)) {
    HARr::write_har(input_har, filename = output_har_file)
  }

  if (!is.null(output_csv_file)) {
    data.table::fwrite(
      x = as.data.frame.table(input_har_no_sets[[1]]),
      file = output_csv_file,
      ...
    )
  }

  return(input_har)
}


```







