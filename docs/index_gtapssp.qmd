---
title: "GTAPSSP: Tools for Integrating Shared Socioeconomic Pathways (SSPs) into the GTAP Framework"
date: today
format:
  bookup-html:
    toc: true
    toc-depth: 6
    number-sections: true
    highlight-style: breeze
    theme:
      light: spacelab
      dark: darkly
    mermaid:
      theme: neutral
  pdf:
    toc: true
    toc-depth: 6
    number-sections: true
    highlight-style: breeze
editor_options: 
  chunk_output_type: console
---

# Introduction

This tutorial demonstrates the utilization of the `gtapssp` package in R for data processing. It covers various steps such as reading, transforming, and analyzing data, making it suitable for both beginners and advanced users. 

The package provides optimized and user-friendly functions to **read** data from ZIP files, **interpolate** data using **spline** and **beers** methods. The *gtapssp* functions is accompanied by detailed [manual](https://github.com/tsimonato/gtapssp/raw/master/docs/gtapssp_0.0.0.9000.pdf), you can also access this manual by running `?gtapssp` in the R console or pressing `F1` on the function name in [RStudio](https://posit.co/download/rstudio-desktop/).

# Installation

To use the *gtapssp* package, it's necessary to have *R* installed on your computer, which can be downloaded from [here](https://www.r-project.org/). Additionally, we recommend downloading *RStudio*, available at [here](https://posit.co/download/rstudio-desktop/), which provides a user-friendly interface to work with *R*.

You can install the development version of *gtapssp* from [GitHub](https://github.com/tsimonato/gtapssp) with:

```{r}
#| label: install
#| echo: true
#| eval: false

# If the devtools package is not already installed, please run the disabled line below.
# install.packages("devtools")
devtools::install_github("tsimonato/gtaptools")
devtools::install_github("tsimonato/gtapssp")
```

# Procedures

We will go through different stages of data manipulation which include reading data from ZIP files, transforming the data format, performing interpolations, and combining data from different sources.

## OECD and IIASA Data

Now, let's read the data from a ZIP file, reshape it, and interpolate it.

```{r}
OECD <- gtapssp::read_csv_from_zip( # <1>
  zip_dir = "Downloads",
  zip_pattern = "OECD",
  csv_pattern = "ssp_snapshot"
) |>
  tidyr::pivot_longer( # <2>
    cols = dplyr::matches(as.character(1500:3000)),
    names_to = "year",
    values_to = "value"
  ) |>
  gtapssp::interpolate_spline( # <3>
    groups = c("Scenario", "Region"),
    year = "year",
    values = "value",
    method = "fmm"
  ) 

# quero excluir os valores duplicados de cada coluna de OECD, ou seja, cada coluna deve ter apenas valores unicos independentemente:
unique_OECD <- OECD |>
  dplyr::select(-value) |> # Exclui a coluna 'value'
  dplyr::summarise(
    dplyr::across(
      dplyr::everything(),
      ~ base::list(base::unique(.))
    )
  ) |>
  base::as.list()


```

1. `read_csv_from_zip` reads CSV files from a ZIP archive, specifying the directory of the files, name file pattern, and name CSV pattern.

2. `pivot_longer` transforms `year` columns from wide format to long format.

3. `interpolate_spline` performs data interpolation for missing years using *fmm* spline method.


We process the IIASA data similarly.

```{r}
pythonExePath <- "C:\\Users\\tsimonat\\AppData\\Local\\Programs\\Python\\Python312\\python.exe"
outputFile <- "data/iiasa_raw.rda"

# load the data saved above
# load("data\\iiasa_raw.rda")

gtapssp::updateData(
  pythonExePath = pythonExePath,
  outputFile = outputFile
)


gtapssp::updateCorresp(
  iiasa_raw = gtapssp::iiasa_raw,
  corresp_reg = gtapssp::corresp_reg_pre,
  outputFile = "data/corresp_reg.rda"
)

# tentar inverter
group_cols <- c("model", "scenario", "reg_iso3", "variable", "unit")

agg_iiasa <- gtapssp::aggData(group_cols = group_cols)

# Aplicar a função interpolate_spline
spline_out <- agg_iiasa |>
  tidyr::drop_na(model) |>
  dplyr::filter(model %in% c("IIASA GDP 2023", "OECD ENV-Growth 2023")) |>
  gtapssp::interpolate_spline(
    groups = group_cols,
    year = "year",
    values = "value"
  )

# Aplicar a função interpolate_beers
beers_out <- agg_iiasa |>
  dplyr::filter(model %in% c("IIASA-WiC POP 2023")) |>
  dplyr::filter(!grepl("^Mean Years of Education", variable)) |>
  gtapssp::interpolate_beers(
    groups = group_cols,
    year = "year",
    values = "value"
  )
beers_out <- beers_out |>
  tidyr::separate_wider_delim( # <3>
    cols = "variable",
    names = c("variable", "gender_code", "cohort", "education_level"),
    delim = "|",
    too_few = "align_start"
  )

# combine vertically the two outputs
gtap_ssp <- dplyr::bind_rows(beers_out, spline_out)


exp_hist <- gtap_ssp |>
  dplyr::filter(scenario == "Historical Reference") |> # Select scenario "Historical Reference" and exclude that column
  dplyr::select(-scenario) |>
  tidyr::expand_grid(scenario = unique(gtap_ssp$scenario)) # Create a new scenario colummn Expanded to all 5 SSPs categories

# Bind the data sets
gtap_ssp <- gtap_ssp |>
  dplyr::anti_join(dplyr::select(exp_hist, -value)) |> # exclude overlappings between SSPs and Historical Reference data
  dplyr::bind_rows(exp_hist) |>
  dplyr::filter(scenario != "Historical Reference") # exclude the old "Historical Reference" set
# Identify unique groups in gtap_ssp
group_columns <- setdiff(names(gtap_ssp), c("scenario", "reg_iso3", "year", "value"))
unique_groups <- gtap_ssp |>
  dplyr::select(dplyr::all_of(group_columns)) |>
  dplyr::distinct()

# Create all combinations of groups with required_regions
complete_data <- unique_groups |>
  tidyr::expand_grid(reg_iso3 = unique(gtapssp::corresp_reg$reg_iso3)) |>
  tidyr::expand_grid(year = unique(gtap_ssp$year)) |>
  tidyr::expand_grid(scenario = unique(gtap_ssp$scenario))

# Ensure all combinations exist in gtap_ssp
gtap_ssp <- complete_data |>
  dplyr::left_join(gtap_ssp, by = c(group_columns,"scenario", "reg_iso3", "year")) |>
  dplyr::mutate(value = tidyr::replace_na(value, 0)) # Fill missing values with 0


# isoList_dt <- read.csv("data/isoList.csv", na.strings = "") # <1>
# educDict_dt <- read.csv("data/educDict.csv", na.strings = "")
# cohortDict_dt <- read.csv("data/cohortDict.csv", na.strings = "")
# genderDict_dt <- read.csv("data/genderDict.csv", na.strings = "")

gtap_ssp2 <-
  gtap_ssp |>
  # dplyr::left_join(isoList_dt, by = dplyr::join_by(Region)) |>  # <2>
  dplyr::left_join(gtapssp::educDict, by = dplyr::join_by(education_level)) |>
  dplyr::left_join(gtapssp::cohortDict, by = dplyr::join_by(cohort)) |>
  dplyr::left_join(gtapssp::genderDict, by = dplyr::join_by(gender_code))

gtap_ssp2 <-
  gtap_ssp2 |>
  dplyr::mutate(
    MOD = model,
    VAR = variable,
    SCE = scenario, # SSPs scenarios
    ISO = reg_iso3, # ISO country codes for geographic identification
    # EDU = educ,             # Education categories, derived from 'educ'
    GND = gender, # Gender information
    AGE = age, # Age groups or categories
    YRS = paste0("Y", year), # Year, formatted with a 'Y' prefix
    POP = value, # Population values
    .keep = "none"
  )

gtap_ssp2 <-
  gtap_ssp2 |>
  dplyr::mutate(
    GND = tidyr::replace_na(GND, "TOTL"),
    AGE = tidyr::replace_na(AGE, "TOTL"),
    # EDU = tidyr::replace_na(EDU, "TOTL")
  )


# gtap_ssp <- gtap_ssp |>
#   dplyr::filter(
#     model != "IIASA-WiC POP 2023" |
#     !is.na(education_level) | # Exkuir totais (NA)
#     scenario == "Historical Reference" | # Nesse cenario so tem NA em educatio_level
#     cohort %in% c("Age 0-4", "Age 5-9", "Age 10-14")) # Essas categorias so tem NA (TOtais) pois nao tem abertura por educatio_level


data_write <- gtap_ssp2 |>
  dplyr::mutate(
    VAR = dplyr::case_when(
      VAR == "GDP|PPP" ~ "GDP_PPP",
      VAR == "GDP|PPP [per capita]" ~ "GDP_PER_CAPI",
      TRUE ~ VAR # Keep other values unchanged
    ),
    # Multiply POP by 1000 if VAR is GDP_PPP
    POP = ifelse(VAR == "GDP_PPP", POP * 1000, POP)
  )

POP <- data_write |>
  dplyr::filter(MOD == "IIASA-WiC POP 2023") |>
  dplyr::filter(GND != "TOTL") |>
  dplyr::group_by(SCE, ISO, GND, YRS, AGE) |>
  dplyr::summarise(POP = sum(POP, na.rm = T))

GDPI = data_write |> 
  tidyr::complete(MOD, VAR, SCE, ISO, YRS, fill = list(POP = 0)) |>
       dplyr::filter(MOD == "IIASA GDP 2023") |> 
        dplyr::filter(VAR != "Population") |> 
       dplyr::group_by(VAR, SCE, ISO, YRS) |> 
  dplyr::summarise(GDPI = sum(POP, na.rm = T))

GDPO <- data_write |>
  dplyr::filter(MOD == "OECD ENV-Growth 2023") |>
  dplyr::group_by(VAR, SCE, ISO, YRS) |>
  dplyr::summarise(GDPO = sum(POP, na.rm = T))


data <- list(
  POP = array(
    POP |>
      dplyr::pull(POP),
    dim = rev(sapply(POP |> dplyr::select(-POP), function(x) length(unique(x)))),
    dimnames = rev(lapply(POP |> dplyr::select(-POP), function(x) unique(x)))
  ) |> aperm(rev(1:(length(POP) - 1))),
  GDPI = array(
    GDPI |>
      dplyr::pull(GDPI),
    dim = rev(sapply(GDPI |> dplyr::select(-GDPI), function(x) length(unique(x)))),
    dimnames = rev(lapply(GDPI |> dplyr::select(-GDPI), function(x) unique(x)))
  ) |> aperm(rev(1:(length(GDPI) - 1))),
  GDPO = array(
    GDPO |>
      dplyr::pull(GDPO),
    dim = rev(sapply(GDPO |> dplyr::select(-GDPO), function(x) length(unique(x)))),
    dimnames = rev(lapply(GDPO |> dplyr::select(-GDPO), function(x) unique(x)))
  ) |> aperm(rev(1:(length(GDPO) - 1)))
)

attr(data$POP, "description") <- "IIASA-WiC POP 2023 (million people)"
attr(data$GDPI, "description") <- "IIASA GDP 2023 (USD_2017/yr)"
attr(data$GDPO, "description") <- "OECD ENV-Growth 2023 (USD_2017/yr)"


HARr::write_har(data, "WIC.har")

devtools::build_manual(path = "docs")



























coffeer::har_write(
  headers = list(
    GDPI = list(
      data = gtap_ssp3_summary |>
  dplyr::filter(MOD == "IIASA GDP 2023"),
      values = "POP",
      sets = c("SCE", "ISO", #"EDU", "GND", "AGE",
               "YRS"),
      coeff = "GDPI",
      name = "IIASA GDP 2023 (billion USD_2017/yr)"
    ),
  
    GDPO = list(
      data = gtap_ssp3_summary |>
  dplyr::filter(MOD == "OECD ENV-Growth 2023"),
      values = "POP",
      sets = c("SCE", "ISO", #"EDU", "GND", "AGE",
               "YRS"),
      coeff = "GDPO",
      name = "OECD ENV-Growth 2023 (billion USD_2017/yr)"
    )#,
  
  #   WIC = list(
  #     data = gtap_ssp3_summary |>
  # dplyr::filter(POP == "IIASA-WiC POP 2023"),
  #     values = "POP",
  #     sets = c("SCE", "ISO", "EDU", "GND", "AGE",
  #              "YRS"),
  #     coeff = "POP",
  #     name = "WIC"
  #   )
  ),
  output_har = "WIC3.har"
)


# gtap_ssp3_summary <- gtap_ssp2 |>
#     dtplyr::lazy_dt() |> 
#   dplyr::filter(MOD == "IIASA-WiC POP 2023") |> 
# 
#   dplyr::group_by(MOD, SCE, ISO, EDU, GND, AGE, 
#                   YRS) |>
#   dplyr::summarize(
#     POP = sum(POP, na.rm = TRUE), # Sum 'value' for each group
#    #count = dplyr::n(),                    # Count number of rows in each group (optional)
#     .groups = "drop"                       # Ungroup after summarization
#   ) |>
#   as.data.frame()

coffeer::har_write(
  headers = list(
    POP = list(
      data = data |>
  dplyr::filter(MOD == "IIASA-WiC POP 2023"),
      values = "POP",
      sets = c("SCE", "ISO", #"EDU",
               "GND",
               "AGE",
               "YRS"),
      coeff = "POP",
      name = "IIASA-WiC POP 2023 (million people)"
    )
  ),
  output_har = "WIC_POP.har"
)

gtaptools::har_shape(
  input_data = list(list(
    input_data = gtap_ssp2 |>
  dplyr::filter(MOD == "IIASA-WiC POP 2023"), # <1>
    header = quote( # <2>
      `POP`[c( # <3>
      "SCE",
      "ISO",
      #"EDU",
      "GND", # <4>
      "AGE",
      "YRS"
    )])
  )),
  output_har_file = "ssp3_gdp3.har" # <5>
)

gtap_ssp3_summary$AGE |> unique()


coffeer::har_write(
  headers = list(
    WIC = list(
      data = gtap_ssp2 |>
  dplyr::filter(MOD == "IIASA-WiC POP 2023"),
      values = "POP",
      sets = c("SCE", "ISO",# "EDU",
               "GND", "AGE",
               "YRS"),
      coeff = "POP",
      name = "WIC"
    )
  ),
  output_har = "WIC2.har"
)





test_har <- HARr::read_har("WIC3.har", toLowerCase =F)$LSHK |> as.data.frame.table()


test_har <- test_har |> 
  dplyr::filter(SCE == "SSP1", ISO == "USA", GND=="FEML", EDU == "NONE", YRS == "Y2023") |> 
  dplyr::pull(Freq)


test_data_write <- data_write |> 
  dplyr::filter(SCE == "SSP1", ISO == "USA", GND=="FEML", EDU == "NONE", YRS == "Y2023") |> 
  dplyr::pull(POP)
  


ascasc














# Define the columns to permute
columns <- c("SCE", "ISO", "GND",
             "EDU", "YRS")

# Generate all permutations of the column order
column_permutations <- gtools::permutations(n = length(columns), r = length(columns), v = columns)

# Initialize result
correct_order_select <- NULL
correct_order_arrange <- NULL

# Iterate over permutations for select and arrange
for (select_perm in seq_len(nrow(column_permutations))) {
  select_order <- column_permutations[select_perm, ]
  # select_order <- c("SCE", "ISO", #"GND",
  #            "EDU", "YRS")
  for (arrange_perm in seq_len(nrow(column_permutations))) {
    arrange_order <- column_permutations[arrange_perm, ]
    # arrange_order <- c("SCE", "ISO", #"GND",
    #          "EDU", "YRS")
    
    # Arrange data by current select and arrange permutation
    data <- data_write |> 
      dplyr::select(dplyr::all_of(c(select_order, "POP"))) |> # Change select order
      dplyr::arrange(dplyr::across(dplyr::all_of(arrange_order)))
    
    # Create HAR file
    har_data <- list(
      LSHK = array(
        data |> dplyr::pull(POP),
        dim = rev(sapply(data |> dplyr::select(-POP), function(x) length(unique(x)))),
        dimnames = rev(lapply(data |> dplyr::select(-POP), function(x) unique(x)))
      ) |> aperm(rev(seq_along(arrange_order)))
    )
    
    HARr::write_har(har_data, "WIC4.har")
    
    # Read and validate
    test_har <- HARr::read_har("WIC4.har", toLowerCase = FALSE)$LSHK |> as.data.frame.table()
   test_har <-  test_har |> 
      dplyr::left_join(data, by = columns)
   
   test_result <- all(abs(round(test_har$Freq, 3) - round(test_har$POP, 3)) <= 1e-2, 
                      na.rm = TRUE)
    
#    # Find mismatched rows
# mismatched_rows <- test_har |>
#   dplyr::filter(
#     abs(Freq - POP) > 1e-2 |  # Allow a small tolerance for floating-point precision
#       (is.na(Freq) != is.na(POP))  # Mismatched NA statuses
#   )
   
    # Check if test_har equals test_data_write
    if (test_result) {
      correct_order_select <- select_order
      correct_order_arrange <- arrange_order
      cat("Matching orders found:\n")
      cat("Select order:", paste(correct_order_select, collapse = ", "), "\n")
      cat("Arrange order:", paste(correct_order_arrange, collapse = ", "), "\n")
      break  # Exit both loops
    }
  }
}

# If no match is found
if (is.null(correct_order_select) || is.null(correct_order_arrange)) {
  cat("No matching orders found.\n")
} else {
  cat("Correct select order is:", paste(correct_order_select, collapse = ", "), "\n")
  cat("Correct arrange order is:", paste(correct_order_arrange, collapse = ", "), "\n")
}











































dtplyr::lazy_dt()





dplyr::group_by()



#gtap_ssp <- gtapssp::growth_rate(data = gtap_ssp)


final_data <- gtapssp::iiasa_gtap(
   aggTxtFile = "data/gtp10_10.agg",
   outFile = "data/output.csv"
 )








gtapssp::corresp_reg$
















# Expanding grid for all combinations of country codes and years
grid <- expand.grid(
  model = unique(gtap_ssp$model)
  reg_gtap_code = unique(gtapssp::corresp_reg$reg_gtap_code),
  year = unique(gtap_ssp$year),
  scenario = c("SSP1", "SSP2", "SSP3", "SSP4", "SSP5")
)







unique(spline_out$year) |> sort()





names(gtap_ssp)


















interpolate <- function(iiasa_raw = gtapssp::iiasa_raw,
                          corresp_reg = gtapssp::corresp_reg,
                       group_cols = c("model", "scenario", "reg_gtap_code", "variable", "unit"),
                          outputFile = NULL){



# Preparar gtap_iiasa2
agg_iiasa <- iiasa_raw$data |>
  dplyr::rename(cty_names = region) |>
  dplyr::right_join(corresp_reg) |>
  dplyr::group_by(dplyr::across(dplyr::all_of(group_cols)), year) |>
  dplyr::summarize(value = sum(value, na.rm = TRUE)) |>
  tidyr::drop_na(model)

# # save objet sem a coluna variable
# gtap_iiasa2 <- gtap_iiasa2 |>
#   dplyr::select(-variable)
# save(gtap_iiasa2, file = "data\\gtap_iiasa.rda")

# Aplicar a função interpolate_spline
spline_out <- gtap_iiasa2 |>
  tidyr::drop_na(model) |>
  dplyr::filter(model %in% c("IIASA GDP 2023", "OECD ENV-Growth 2023")) |>
  gtapssp::interpolate_spline(
    groups = group_cols,
    year = "year",
    values = "value"
  )

# Aplicar a função interpolate_beers
beers_out <- gtap_iiasa2 |>
  dplyr::filter(model %in% c("IIASA-WiC POP 2023")) |>
  gtapssp::interpolate_beers(
    groups = group_cols,
    year = "year",
    values = "value"
  )

# combine vertically the two outputs and expand variable column
gtap_ssp <- dplyr::bind_rows(beers_out, spline_out) |>
  tidyr::separate_wider_delim( # <3>
    cols = "variable",
    names = c("variable", "gender", "cohort", "education_level"),
    delim = "|",
    too_few = "align_start"
  )


# Get all columns except 'year' and 'value' for grouping
#group_cols <- setdiff(names(gtap_ssp), c("year", "value"))

# tem grupos dentro de populacao que tem education NA e ate cohort NA, sao agregacoes dos grupos nao-NA ou sao residuos? Checar isso e se for agregacap. devemos deletar os POPpulation q tem essas colunas NA

# gtap_ssp2 <- gtap_ssp |>
#   dplyr::group_by(dplyr::across(dplyr::all_of(group_cols))) |>
#   dplyr::mutate(value_rate = value / dplyr::lag(value) - 1)
  

gtap_ssp <- gtap_ssp |>
  dplyr::filter(!is.na(education_level) | # Exkuir totais (NA)
                  scenario == "Historical Reference" | # Nesse cenario so tem NA em educatio_level
                  cohort %in% c("Age 0-4", "Age 5-9", "Age 10-14")) # Essas categorias so tem NA (TOtais) pois nao tem abertura por educatio_level

return(gtap_ssp)

}































# gtap_ssp2 <- gtap_ssp |>
#   dplyr::filter(
#     !is.na(education_level) |
#           scenario == "Historical Reference" |
#           cohort %in% c("Age 0-4", "Age 5-9", "Age 10-14"))



unique_gtap_ssp2 <- gtap_ssp2 |>
  dplyr::summarise(
    dplyr::across(
      dplyr::everything(),
      ~ base::list(base::unique(.))
    )
  ) |>
  base::as.list()



reg <- gtap_ssp2$reg_gtap_code |> unique() |> tolower()
reg

reg_sets <- HARr::read_har("data/sets.har")$h1
reg_sets


# ISO3 em reg mas não em reg_sets
only_in_reg <- base::setdiff(reg, reg_sets)

# ISO3 em reg_sets mas não em reg
only_in_reg_sets <- base::setdiff(reg_sets, reg)



reg["zaf"]

# Downloading the United Nations GDP data
download.file(
  "https://unstats.un.org/unsd/amaapi/api/file/2",
  "./UN-NAData.xlsx",
  method = "curl"
)

# Reading the downloaded file and skipping the first 2 rows
UN_base <- readxl::read_excel("./UN-NAData.xlsx", skip = 2)

# Filtering for the specific indicator: 'Gross Domestic Product (GDP)'
UN_gdp <- UN_base |>
  #dplyr::filter(IndicatorName == "Gross Domestic Product (GDP)") |>
  # Pivoting the data from wide to long format
  tidyr::pivot_longer(
    cols = dplyr::matches(as.character(1500:3000)),
    names_to = "year",
    values_to = "value_un"
  ) |>
  # Filtering out unnecessary rows based on specific in the 'Country' column
  dplyr::filter(!grepl("(Former)|Zanzibar|Kosovo|Micronesia", Country)) |>
  # Transforming the data to include ISO3 country codes, year, and GDP values
  dplyr::transmute(
    iso3c = countrycode::countryname(
      Country,
      destination = "iso3c",
      warn = F
    ),
    year = as.numeric(year),
    gdp_un = value_un
  )






unique_UN_gdp <- UN_gdp |>
  dplyr::summarise(
    dplyr::across(
      dplyr::everything(),
      ~ base::list(base::unique(.))
    )
  ) |>
  base::as.list()

















sum(gtap_ssp2$value)

filtered_data <- gtap_ssp2 |>
  dplyr::filter(
    model == "IIASA-WiC POP 2023", # Substitua pelo modelo desejado
    scenario == "SSP1",            # Substitua pelo cenário desejado
    year == 2020                   # Substitua pelo ano desejado
  ) |> 
  dplyr::pull(value) |>
  sum()

# Exibindo o resultado
filtered_data


gtap_ssp2 |>
  dplyr::filter(
    model == "IIASA-WiC POP 2023", # Substitua pelo modelo desejado
    scenario == "Historical Reference",            # Substitua pelo cenário desejado
    year == 2020#,                   # Substitua pelo ano desejado
   # is.na(gender)
  ) |> 
  dplyr::pull(value) |>
  sum(na.rm = T)

a <- gtap_ssp2 |>
  dplyr::select(scenario, gender, cohort, education_level, year) |> 
  unique()
  







iiasa_raw$meta













IIASA <- gtapssp::read_csv_from_zip(
  zip_dir = "Downloads",
  zip_pattern = "IIASA", # <1>
  csv_pattern = "ssp_snapshot"
) |>
  tidyr::pivot_longer(
    cols = dplyr::matches(as.character(1500:3000)),
    names_to = "year",
    values_to = "value"
  ) |>
  gtapssp::interpolate_spline(
    groups = c("Scenario", "Region"),
    year = "year",
    values = "value"
  )
```

1. The `IIASA` field specifies the pattern to match the ZIP file names.

## WIC Data

Additional processing is done for the WIC dataset. This includes transformations and analysis with the `interpolate_beers` function.

### WIC data processing steps

```{r warning=FALSE}
#| message: false
WIC <- gtapssp::read_csv_from_zip( # <1>
  zip_dir = "Downloads",
  zip_pattern = "WIC",
  csv_pattern = "ssp_snapshot"
)

WIC <- WIC |>
  tidyr::pivot_longer( # <2>
    cols = dplyr::matches(as.character(1500:3000)),
    names_to = "year",
    values_to = "value"
  )

WIC <- WIC |>
  tidyr::separate_wider_delim( # <3>
    cols = "Variable",
    names = c("var", "gender_code", "cohort", "education_level"),
    delim = "|",
    too_few = "align_start"
  ) |>
  dplyr::mutate(year = as.integer(year)) # <4>

WIC <- gtapssp::interpolate_beers( # <5>
  input_df = WIC,
  groups = c("Scenario", "Region", "gender_code", "cohort", "education_level"),
  year = "year",
  values = "value",
  method = "ordinary"
)


# fread in csv: "C:\Users\tcsim\OneDrive\purdue_postdoc\projects\ssp\SSPV3\WIC_All_int.csv"
# i want to data.table::fread in this path: "C:\Users\tcsim\OneDrive\purdue_postdoc\projects\ssp\SSPV3\WIC_All_int.csv"

#WIC_test <-  data.table::fread("C:/Users/tcsim/OneDrive/purdue_postdoc/projects/ssp/SSPV3/WIC_All_int.csv", na.strings = "")


```

1. This command reads CSV files from a ZIP archive located in the `Downloads` directory. The function targets files with the `WIC` pattern in their name and specifically looks for files that contain `ssp_snapshot` in their name.
2. `pivot_longer` transforms `year` columns from wide format to long format.
3. The `separate_wider_delim` function is used to split the `Variable` column into multiple columns based on a delimiter `|`. This creates new columns `var`, `gender_code`, `cohort`, and `education_level`.
4. Finally, `dplyr::mutate` is used to convert the `year` column to integer type for consistent data handling.
5. `interpolate_beers` performs data interpolation for missing years using *ordinary* beers method.

### Labeling and Cleaning Data for Export

In this step, we prepare our WIC data for export by labeling and cleaning it to ensure it's in the correct format. This involves reading additional data sets and merging them with our main dataset.

```{r}
isoList_dt <- read.csv("data/isoList.csv", na.strings = "")  # <1>
educDict_dt <- read.csv("data/educDict.csv", na.strings = "")
cohortDict_dt <- read.csv("data/cohortDict.csv", na.strings = "")
genderDict_dt <- read.csv("data/genderDict.csv", na.strings = "")

WIC <- 
  WIC |> 
  dplyr::left_join(isoList_dt, by = dplyr::join_by(Region)) |>  # <2>
  dplyr::left_join(educDict_dt, by = dplyr::join_by(education_level)) |> 
  dplyr::left_join(cohortDict_dt, by = dplyr::join_by(cohort)) |> 
  dplyr::left_join(genderDict_dt, by = dplyr::join_by(gender_code))
```

1. Each `read.csv` call reads a different CSV file containing essential data. The `na.strings = ""` parameter treats empty strings as `NA` values.
2. The WIC data is joined with the additional datasets using the `dplyr::left_join`.

Finally, `dplyr::transmute` is used to transform and rename columns, resulting in a dataset ready to be exported:

```{r}
WIC <- 
  WIC |> 
  dplyr::mutate(
    SCE = Scenario,         # SSPs scenarios
    ISO = iso,              # ISO country codes for geographic identification
    EDU = educ,             # Education categories, derived from 'educ'
    GND = gender,           # Gender information
    AGE = age,              # Age groups or categories
    YRS = paste0("Y", year),# Year, formatted with a 'Y' prefix
    POP = value,             # Population values
    .keep = "none"
  )

a <- WIC |> 
  dplyr::group_by(YRS, SCE) |>
  dplyr::summarize(
    sum = sum(POP) # Sum of population values
  )

```



# Export to a HAR file

```{r}

# arrange for all variables
a <- 
  WIC |>
  dplyr::arrange(SCE, ISO, EDU, GND, AGE, YRS)


gtaptools::har_shape(
  input_data = list(list(
    input_data = WIC2, # <1>
    header = quote( # <2>
      `POP`[c( # <3>
      "SCE",
      "ISO",
      "EDU",
      "GND", # <4>
      "AGE",
      "YRS"
    )])
  )),
  output_har_file = "ssp3_gdp.har" # <5>
)



WIC2 <- WIC |>
  coffeer::order_data(
    ordering_list = list(
      SCE = unique(WIC$SCE),
      ISO = unique(WIC$ISO),
      EDU = unique(WIC$EDU),
      GND = unique(WIC$GND),
      AGE = unique(WIC$AGE),
      YRS = unique(WIC$YRS)
    )
  ) |> 
  as.data.frame()

coffeer::har_write(
  headers = list(
    WIC = list(
      data = WIC2,
      values = "POP",
      sets = c("SCE", "ISO", "EDU", "GND", "AGE", "YRS"),
      coeff = "WIC",
      name = "WIC"
    )
  )
  output_har = "WIC.har"
)






```

1. The `input_data` parameter specifies the dataset to be exported.
2. The `header` parameter defines the columns to be included in the output file.
3. The `POP` column is selected for export, with specific columns included in the output file.
4. The `GND` column is commented out to exclude it from the output file.
5. The `output_har_file` parameter specifies the name of the HAR file to be created.









```{r}
har_shape <- function(input_data,
                      useCoefficientsAsNames = F,
                      #new_calculated_vars = NULL,
                      del_headers = NULL,
                      export_sets = T,
                      output_har_file = NULL,
                      as_dataframes = T) {
  #' @name har_shape
  #' @title Bind data bases and generate/change headers.
  #'
  #' @description Allows the combination of different databases in data.frame or array format. Generate new variables flexibly from custom functions. Calculations can be performed between headers/variables of different dimensions/sets.
  #'
  #' @param input_data It must consist of one or more input databases, which must be separated from each other by sublists (see example). In the case of multiple databases, all will be combined for the final output.Arrays and data.frames must be inside sublists (list(....)) as indicated in the examples section. Aggregations on input data can only be performed on single array and data.frame inputs.
  #' @param useCoefficientsAsNames If a coefficient name is present in the header, use that instead of the four-letter header (default = F)
#  #' @param new_calculated_vars New variables resulting from custom calculations between the headers contained in #input_data. The header_name[c("its sets")] format must be adopted. The new header generated by the calculation will #be aggregated by sum in the sets indicated for it. Please check the examples section and the package's online manual #for more details.
  #' @param del_headers Vector of characters with the names of headers that must be excluded from the output.
  #' @param export_sets If a name for a .har file is indicated, all sets will exported to that .har file. If TRUE the sets will included in output_har_file, if FALSE the sets will not be written anywhere. (default = TRUE)
  #' @param output_har_file Output .har file name.
  #' @param as_dataframes Converts each sublist to data.frame format (default = T).
  #'
  #' @importFrom HARr write_har read_har
  #' @import data.table
  #'
  #' @note
  #'
  #' 1. The calculations indicated in the new_calculated_vars variable are processed sequentially. Therefore, if the calculation for generating a new header depends on another header that will also be generated within new_calculated_vars, the second one must be defined first.
  #'
  #' 2. Ensure that the .har files adopted as input_data have an adequate structure, including the declaration of sets for each file header. It prevents the output_har_file from being recorded with errors that make it impossible for the file to be opened by the Viewhar software later.
  #'
  #' @examples
  #' # example code
  #'
  #' # - The list_df is composed by list_df, a list of input data
  #' #    (path to a .har database(1), data.frame(2), list of arrays(3), array(4)).
  #'
  #' path_to_har <- gtaptools::templates("oranig_example.har")
  #'
  #' list_db <- list(
  #'   path_to_har, # 1 - path to .har database
  #'   list(
  #'     input_data = gtaptools::example_df, # 2 - data.frame
  #'     header = quote(`1MAR`[c("COM", "SRC", "IND", "MAR")])
  #'   ),
  #'   gtaptools::example_arrays_har, # 3 - list of arrays
  #'   list(
  #'     input_data = gtaptools::example_arrays_har$XPLH, # 4 - array
  #'     header = quote(`XPLH`[c("COM", "HOU")])
  #'   )
  #' )
  #'
  #' # - calcs defines the calculations that aggregate (1),
  #' #    solve a matrix (2) and create a header (3).
  #'
  #' calcs <- list(
  #'   quote(MARC["COM"] := `1MAR`), # Sums to set COM
  #'   quote(MULT[c("REG", "HOU")] := solve(MAKE)), # Solves the matrix
  #'   quote(NSET := c("Comm1", "Comm2")) # Creates sets
  #' )
  #'
  #'
  #' # - new_binded_db is a list object that combines the databases
  #' #    contained in list_df and the calculations described in calcs.
  #' #   Also, the "3PUR" header will not be included in the data output
  #' #    to "gtaptools_shape_example.har", while the sets are being
  #' #    written to "gtaptools_shape_example_sets.har"
  #'
  #'
  #' new_binded_db <-
  #'   gtaptools::har_shape(
  #'     input_data = list_db,
  #'     new_calculated_vars = calcs,
  #'     del_headers = c("3PUR"),
  #'     export_sets = "gtaptools_shape_example_sets.har",
  #'     output_har_file = "gtaptools_shape_example.har"
  #'   )
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #'
  #' @export

  #
  #   output_har_file = "test.har"
  #   del_header <- "MAKE"
  #
  #   input_data_text <- "data/test/teste/input/REG_DYN_HOU.har"
  #   input_data1 <- HARr::read_har(input_data_text,
  #     useCoefficientsAsNames = F,
  #     toLowerCase = F
  #   )
  #
  #   input_data2 <- input_data1$MAKE |> as.data.frame.table()
  #   input_data3 <- input_data1$BSMR |> as.data.frame.table()
  #   input_data4 <- input_data1$HOU
  #   input_data5 <- input_data1$MAKE
  #
  #
  #   1.04313517 + 23.37448354
  #
  #   1.04313517 + 23.37448354
  #
  #   log(19078.02545586)
  #
  #
  #   new_calculated_vars <- list(
  #     list(
  #       x = "MAKE",
  #       y = "BSMR",
  #       #z = "TFRO",
  #       fun = function(x, y) x + y,
  #       new_header = "MCID",
  #       new_sets = c("COM", "DST")
  #     ),
  #     list(
  #       x = "BSMR",
  #       fun = function(x) log(x),
  #       new_header = "BSMC",
  #       new_sets = c("COM")
  #     ),
  #     list(
  #       x = "BSMR",
  #       fun = function(x) sum(x),
  #       new_header = "BSCS",
  #       new_sets = c("COM", "SRC")
  #     )
  #   )
  #
  #   input_data <- list(
  #     input_data1,
  # list(
  #   input_data = input_data2,
  #   sets = c("COM", "IND", "DST"),
  #   values = "Freq",
  #   new_header_name = "MAKE"
  # ),
  # list(
  #   input_data = input_data3,
  #   sets = c("COM", "SRC"),
  #   values = "Freq",
  #   new_header_name = "MAKE"
  # ),
  # list(
  #   input_data = input_data4,
  #   new_header_name = "HOU"
  # )
  # )




  # new_derived_vars <- list(
  #   list(
  #     input_header = "MAKE",
  #     new_header = "MAK4",
  #     new_header_dim = c("COM", "IND")
  #   ),
  #   list(
  #     input_header = "BSMR" ,
  #     new_header = "BSM2",
  #     new_header_dim = "COM"
  #   )
  # )


  # l <- 1
  
  
  
  input_data = list(list(input_data = WIC2, # <1>
                         header = quote(# <2>
                           `POP`[c(# <3>
                             "SCE",
                             "ISO",
                             "EDU",
                             "GND", # <4>
                             "AGE",
                             "YRS")])))
    
    
    
  output_har_file = "ssp3_gdp.har" # <5>
                      useCoefficientsAsNames = F
                      new_calculated_vars = NULL
                      del_headers = NULL
                      export_sets = T
                      as_dataframes = T
  
  
  # non_obj <-
  #   unlist(input_data[!sapply(input_data, function(x)
  #     is.object(x) & is.list(x))], recursive = F)
  # obj <- input_data[sapply(input_data, is.object)]
  # input_data <- c(non_obj, obj)
                      
    
 complete_data <- function(input_data, group = NULL, values, fill_value = NA) {
  original_class <- class(input_data)
  
  # Handle array input by converting it to a data.frame
  if (is.array(input_data)) {
    dim_names <- dimnames(input_data)
    group = names(dim_names)
    input_data <- as.data.frame.table(input_data)
    names(input_data) <- c(group, values)
    for (i in seq_along(group)) {
      input_data[[group[i]]] <- factor(input_data[[group[i]]], levels = dim_names[[i]])
    }
  }
  
  # Ensure input_data is compatible with data.table operations
  if (!inherits(input_data, "data.table")) {
    data.table::setDT(input_data)
  }
  
  # Generate all combinations of group columns
  all_combos <- do.call(data.table::CJ, c(lapply(input_data[, ..group, with = FALSE], unique), sorted = FALSE))
  
  # Perform a right join to keep all combinations using all.x = TRUE
  expanded_data <- merge(all_combos, input_data, by = group, all = TRUE)
  
  # Fill NA values in specified 'values' columns with 'fill_value'
  for (value_col in values) {
    if (value_col %in% names(expanded_data)) {  # Check if the column actually exists
      if (!is.na(fill_value)) {  # Only set NAs if a fill_value is specified
        expanded_data[is.na(expanded_data[[value_col]]), (value_col) := fill_value]
      }
    } else {
      warning(sprintf("Column '%s' not found in input data. No values filled.", value_col))
    }
  }
  
  # Return the data in its original format
  if (original_class[1] == "array") {
    return(array(expanded_data[[values]], dim = dim(expanded_data[, ..group, with = FALSE]), dimnames = lapply(expanded_data[, ..group, with = FALSE], unique)))
  } else if (original_class[1] == "data.frame") {
    return(as.data.frame(expanded_data))
  } else {
    return(expanded_data)
  }
}
  
  adj_input <- function(input_array, sets, values) {
            
  completed_data =
    complete_data(
      input_data = input_array,
      group = sets,
      values = values,
      fill_value = 0
    ) |> as.data.frame()
  
 dim = rev(lapply(completed_data[sets], function(x) length(unique(x))))
 dimnames = rev(lapply(completed_data[sets], unique)) 
 order_array <- rev(1:(length(lapply(completed_data[sets], unique))))
 
new_array = array(
    as.numeric(completed_data[[values]]),
    dim = dim,
    dimnames = dimnames
  ) |> aperm(order_array)

  return(new_array)

}
  
input_data[[1]]$input_data

adj_input( input_array = input_data[[1]]$input_data, 
           sets = c("SCE", "ISO", "EDU", "GND", "AGE", "YRS"), 
           values = "POP")

  input_har <- c()
  for (l in 1:length(input_data)) {
    input <- input_data[[1]]
    
    # for (l in 1:length(input_har)) {
    #   if (is.data.frame(input_har[[l]])) {
    #     input <- as.array(input_har[[l]],
    #                       responseName = names(input_har[l]))
    #   }
    # }

    # if (is.array(input)) {
    #   stop("One or more elements of the input database list (input_data) is an array. Please insert it into a sublist and describe its new_header_name, and sets in a format new_header_name[c(its sets)].")
    # }

    if (length(input) == 1) {
      if ((is.character(input[[1]]) & grepl("*.har", input[[1]]))) {
        input <- HARr::read_har(input[[1]], toLowerCase = F,
                                useCoefficientsAsNames = useCoefficientsAsNames)

        input_har_diff <- base::setdiff(names(input_har), names(input))
        input_har <- c(input_har[input_har_diff], input)
      }
    } else if (!substr(names(input)[1], 1, 2) == "XX") {
      if (!is.null(input$input_data)) {
        sets = eval(input$header[[3]])
        values = as.character(input$header[[2]])
        input <- summarise_header(
          input_data = input$input_data,
          header = input$header,
          fun = function(x) sum(x, na.rm = T)
        )
       input <-  adj_input(
         input_array = input[[values]], 
           sets = sets, 
           values = values)
        
        input_har_diff <- base::setdiff(names(input_har), names(input))
        input_har <- c(input_har[input_har_diff], input)
      } else {
        input_har_diff <- base::setdiff(names(input_har), names(input))
        input_har <- c(input_har[input_har_diff], input)
      }
    }
  }
  
  # if (!is.null(new_calculated_vars)) {
  #   for (v in 1:length(new_calculated_vars)) {
  #     expr <- new_calculated_vars[[v]][[3]]
  # 
  #     dim_adj <- function(x) {
  #       if (is.array(x) & length(dim(x)) == 1) {
  #         x <- c(x)
  #       }
  #       return(x)
  #     }
  #     input_har_1_dim_adj <- lapply(input_har, dim_adj)
  # 
  #     result_calc <- with(input_har_1_dim_adj, eval(expr))
  # 
  #     if (is.character(result_calc)) {
  #       new_header_name <- new_calculated_vars[[v]][[2]]
  #       input_har[[new_header_name]] <- NULL
  #       input_har[[new_header_name]] <- result_calc
  #     } else {
  #       if (length(new_calculated_vars[[v]][[2]]) == 1) {
  #         new_h <- new_calculated_vars[[v]][[2]]
  #         stop(paste0(
  #           "New Header and its sets were not properly described: ",
  #           new_h,
  #           '. Please, describe it in a format: new_header_name[c("its sets")].'
  #         ))
  #       }
  # 
  #       sets <- new_calculated_vars[[v]][[2]][[3]]
  # 
  #       if (is.null(names(dimnames(result_calc)))) {
  #         result_calc <- as.array(result_calc)
  #         names(dimnames(result_calc)) <- eval(sets)
  #       } else {
  #         result_calc <- apply(result_calc, eval(sets), sum)
  #         if (is.null(names(dimnames(result_calc)))) {
  #           result_calc <- as.array(result_calc)
  #           names(dimnames(result_calc)) <- eval(sets)
  #         }
  #       }
  # 
  #       new_header_name <- new_calculated_vars[[v]][[2]][[2]]
  #       input_har[[new_header_name]] <- NULL
  #       input_har[[new_header_name]] <- result_calc
  #     }
  #   }
  # }

  if (!is.null(del_headers)) {
    input_har <- input_har[!names(input_har) %in% del_headers]
  }
  
  
  # create_ordering_list <- function(data_frame, fields) {
  #   ordering_list <- lapply(fields, function(field) {
  #     if (field %in% names(data_frame)) {
  #       unique(data_frame[[field]])
  #     } else {
  #       NULL  # If the field does not exist in 'data_frame', return NULL (default order)
  #     }
  #   })
  #   names(ordering_list) <- fields
  #   return(ordering_list)
  # }
  # 
  # 
  # 
  # # Create ordering list
  # ordering_list <- create_ordering_list(WIC, fields_to_order_by)
  # 
  # input_har <-  order_data(
  #   input_har,
  #   ordering_list = list(
  #     SCE = unique(WIC$SCE),
  #     ISO = unique(WIC$ISO),
  #     EDU = unique(WIC$EDU),
  #     GND = unique(WIC$GND),
  #     AGE = unique(WIC$AGE),
  #     YRS = unique(WIC$YRS)
  #   )
  # )
  #   input_har <-  as.data.frame(input_har)
    
    
  sets <- lapply(input_har, function(x) dimnames(x))
  sets <- unlist(sets, recursive = FALSE)
  names(sets) <- substr(names(sets), nchar(names(sets)) - 2, nchar(names(sets)))
  sets <- sets[unique(names(sets))]
  input_har_diff <- base::setdiff(names(input_har), names(sets))
  
  complete_data <- function(input_data, group, values, fill_value = NA) {
  # Ensure input_data is compatible with data.table operations
  if (!inherits(input_data, "data.table")) {
    data.table::setDT(input_data)
  }
  
  # Generate all combinations of group columns
  all_combos <- do.call(data.table::CJ, c(lapply(input_data[, ..group, with = FALSE], unique), sorted = FALSE))
  
  # Perform a right join to keep all combinations using all.x = TRUE
  expanded_data <- merge(all_combos, input_data, by = group, all = TRUE)
  
  # Fill NA values in specified 'values' columns with 'fill_value'
  for (value_col in values) {
    if (value_col %in% names(expanded_data)) {  # Check if the column actually exists
      if (!is.na(fill_value)) {  # Only set NAs if a fill_value is specified
        expanded_data[is.na(expanded_data[[value_col]]), (value_col) := fill_value]
      }
    } else {
      warning(sprintf("Column '%s' not found in input data. No values filled.", value_col))
    }
  }
  
  # Convert back to data.frame if originally a data.frame
  if (!inherits(input_data, "data.table")) {
    return(as.data.frame(expanded_data))
  }
  
  return(expanded_data)
}

  input_data[[1]]$input_data <-
    complete_data(
      input_data[[1]]$input_data,
      group = names(sets),
      values = input_har_diff,
      fill_value = 0
    )
  
 dim = rev(lapply(input_har[names(sets)], length))
 dimnames = rev(lapply(input_har[names(sets)], unique)) 
 order_array <- rev(1:(length(lapply(input_har[names(sets)], unique))))
 
data <- list(
  DAT = array(
    as.numeric(input_har[!names(input_har) %in% names(sets)][[1]]),
    dim = dim,
    dimnames = dimnames
  ) |> aperm(order_array)
)


  if (is.character(export_sets)) {
    HARr::write_har(sets, filename = export_sets)
  } else if (!export_sets | is.character(export_sets)) {
    input_har <- input_har[input_har_diff]
  } else if (export_sets) {
    input_har <- c(sets, input_har[input_har_diff])
  }
        
        
  input_har      


  if (!is.null(output_har_file)) {
    HARr::write_har(data, filename = output_har_file)
  }

  if (as_dataframes) {
    for (l in 1:length(input_har)) {
      if (is.array(input_har[[l]])) {
        input_har[[l]] <- as.data.frame.table(input_har[[l]],
                                              responseName = names(input_har[l]))
      }
    }
  }

  return(input_har)
}



summarise_header <- function(input_data,
                             header,
                             fun = function(x) sum(x, na.rm = T),
                             export_sets = T,
                             output_har_file = NULL,
                             output_csv_file = NULL,
                             ...) {
  #' @name summarise_header
  #' @title Aggregates headers of data in .har structure.
  #'
  #' @description Summarizes a single database to an array compatible format for writing to .har files.
  #'
  #' @param input_data An array that has the output structure of the read_har function or a data.frame.
  #' @param header Must be adopted the format header_name[c("its sets")], where the header_name must be the same name of the numeric values column in case of a data.frame input_data, and the "its sets" must be the same name of the categorical columns of that data.frame. Please check the examples section and the package's online manual for more details.
  #' @param fun Function used for aggregation in case of non-unique values in sets (default = sum).
  #' @param export_sets If TRUE, the vectors with the set elements are incorporated with the output. If an output .har file is indicated, it will be created and exported to that .har file. If FALSE, they will not be exported.
  #' @param output_har_file Output .har file name.
  #' @param output_csv_file Output .csv file name.
  #' @param ... Any additional arguments to be used to write the .csv file through data.table::fwrite, such as separator character (sep = ","), the character for decimal points (dec = "."), etc.
  #'
  #' @return An array or vector of characters (sets) structured in a compatible way to compose a .har file.
  #'
  #' @importFrom HARr read_har write_har
  #' @import data.table
  #'
  #' @examples
    #' # example code
    #' 

  #'
  #'
  #' @export
  #
  #   path_to_folder <- system.file("extdata", package="gtaptools")
  #
  #   data_example <- mtcars
  #   iris
  #
  #   gtaptools::summarise_header(
  #     input_data = data_example,
  #     sets = c("mpg", "cyl", "am"),
  #     values = "hp",
  #     fun = function(x) sum(x, na.rm = T),
  #     new_header_name = "CARS",
  #     export_sets = T,
  #     output_har_file = "cars_example.har"
  #   )
  #
  #
  #   input_data = data_example
  #   sets = c("mpg", "cyl", "am")
  #   values = "hp"
  #   fun = function(x) sum(x, na.rm = T)
  #   new_header_name = "CARS"
  #   export_sets = T
  #   output_har_file = "cars_example.har"


  #
  # new_var <- NULL
  # input_data_text <- "data/test/teste/input/REG_DYN_HOU.har"
  # input_data <- HARr::read_har(input_data_text,
  #   useCoefficientsAsNames = F,
  #   toLowerCase = F
  # )
  #
  # input_data2 <- input_data1$MAKE |> as.data.frame.table()
  # input_data3 <- input_data1$BSMR |> as.data.frame.table()
  # input_data3 <- input_data1$BSMR
  # input_data4 <- input_data1$HOU
  #
  # input_data <- input_data2
  #
  #
  #
  #
  #
  #
  #
  #   new_calculated_vars <- list(
  #     list(
  #       x = "MAKE",
  #       y = "1CAP",
  #       z = "TFRO",
  #       fun = function(x, y, z) sum(x + y + z),
  #       new_header = "XXXX",
  #       new_dim_cols = c("COM", "IND", "DST")
  #     ),
  #     list(
  #       x = "BSMR",
  #       fun = function(x) log(x),
  #       new_header = "YYYY",
  #       new_dim_cols = c("COM")
  #     ),
  #     list(
  #       x = "BSMR",
  #       fun = function(x) sum(x),
  #       new_header = "MAK4",
  #       new_dim_cols = c("COM", "SRC")
  #     )
  #   )
  #
  #
  #   input_data <- list(
  #     input_data1,
  #     list(
  #       data = input_data2,
  #       dim_cols = c("COM", "IND", "DST"),
  #       values = "Freq",
  #       name_header = "MAKE"
  #     ),
  #     list(
  #       data = input_data3,
  #       dim_cols = c("COM", "SRC", "USR", "DST"),
  #       values = "Freq",
  #       name_header = "MAKE2"
  #     ),
  #     list(
  #       data = input_data4,
  #       name_header = "HOU"
  #     )
  #   )




  # new_derived_vars <- list(
  #   list(
  #     input_header = "MAKE",
  #     new_header = "MAK4",
  #     new_header_dim = c("COM", "IND")
  #   ),
  #   list(
  #     input_header = "BSMR" ,
  #     new_header = "BSM2",
  #     new_header_dim = "COM"
  #   )
  # )

  # df_data = input_data2
  # sets = c("COM", "IND")
  # values = "Freq"
  # new_header_name = "OOOOO"
  #
  #
  # input_data=input_data2
  # sets = c("COM", "IND")
  # values = "Freq"
  # new_header_name = "OOOO"
  # fun = function(x) sum(x, na.rm = T)
  # output_har_file = "Test.har"
  #
  #
  # # input <- input_data1$BSMR
  #
  # df_data <- input$data

  sets <- eval(header[[3]])
  col_values <- as.character(header[[2]])
  new_header_name <- col_values

  if (!(is.data.frame(input_data) | is.array(input_data) | is.list(input_data))) {
    if (is.character(input_data) & grepl("*.har", input_data)) {
      input_data <- HARr::read_har(input_data, toLowerCase = F) # [[tolower(header)]]
      col_values <- "Freq"
    } else {
      stop("Input_data must be a data.frame, array or a path to a .har file.")
    }
  }

  # sets <- tolower(sets)

  summ_header <- function(input_data,
                          header = header,
                          fun = function(x) sum(x, na.rm = T)) {
    sets <- eval(header[[3]])
    col_values <- as.character(header[[2]])
    new_header_name <- col_values

    if (!(is.data.frame(input_data) | is.array(input_data) | is.character(input_data))) {
      stop("The input data is not a data.frame, array or a vector of characters (sets).")
    }

    if (nchar(col_values) > 4) {
      stop("The name of the new header must have up to 4 characters.")
    }

    if (is.array(input_data)) {
      input_data <- as.data.frame.table(input_data)
      col_values <- "Freq"
    }


    test <- !c(sets, col_values) %in% names(input_data)
    if (any(test)) {
      cols_null <- c(sets, col_values)[test]
      stop(paste0(col_values, ": The ", paste0(cols_null, collapse = ", "), " columns indicated in the sets and/or values parameters are not found in the input database."))
    }


    col_values <- ifelse(is.null(col_values), "Freq", col_values)

    df_data <- as.data.frame(input_data)
    df_data <- df_data[c(sets, col_values)]
    df_data[[col_values]] <- as.numeric(df_data[[col_values]])
    # df_data <- data.table::as.data.table(df_data)
    df_data <- data.table::setDT(df_data)[, lapply(.SD, fun), by = c(sets)]
    df_data <- as.data.frame(df_data)

    dim_info <- df_data[sets]
    dim <- sapply(dim_info, function(x) length(unique(x)))
    dimnam <- sapply(dim_info, function(x) unique(x))

    if (!is.list(dimnam)) {
      dimnam <- as.list(as.data.frame(dimnam))
    }

    if (any(nchar(names(dim)) > 3) & !any(names(dim) == "YEAR")) {
      stop("Set names must be up to 3 characters.")
    }

    har_data <- c()
    har_data[[new_header_name]] <- array(
      data = df_data[[col_values]],
      dim = dim,
      dimnames = dimnam
    )

    return(har_data)
  }


  input_har <- c()
  if (!is.character(input_data)) {
    # if (is.array(input_data)) {
    #   col_values <- ifelse(is.null(col_values), "Freq", col_values)
    # }

    input_har <- summ_header(input_data,
      header = header,
      fun = fun
    )

    input_har_no_sets <- input_har
    if (export_sets == T) {
      input_har <- c(input_har, dimnames(input_har[[new_header_name]]))
    }
    if (is.character(export_sets)) {
      HARr::write_har(dimnames(input_har[[new_header_name]]),
        filename = export_sets
      )
    }
  } else {
    input_data <- input_data[input_data != "NA"]
    input_data <- input_data[input_data != ""]
    input_data <- input_data[!is.na(input_data)]
    input_data <- na.omit(input_data)
    input_har[[new_header_name]] <- unique(as.character(input_data))
  }


  if (!is.null(output_har_file)) {
    HARr::write_har(input_har, filename = output_har_file)
  }

  if (!is.null(output_csv_file)) {
    data.table::fwrite(
      x = as.data.frame.table(input_har_no_sets[[1]]),
      file = output_csv_file,
      ...
    )
  }

  return(input_har)
}


```







